{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577a4999-4b31-4732-92a2-02d55ac3b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\caham\\appdata\\local\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\caham\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\caham\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\caham\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\caham\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\caham\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: holidays in c:\\users\\caham\\appdata\\local\\anaconda3\\lib\\site-packages (0.68)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\caham\\appdata\\local\\anaconda3\\lib\\site-packages (from holidays) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\caham\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil->holidays) (1.16.0)\n",
      "         date  GB00010023  GB00010062  GB00011039  GB00012044  GB00012047  \\\n",
      "0  2022-01-01       449.0         0.0       158.0         0.0         0.0   \n",
      "1  2022-01-02       748.0       367.0       275.0       207.0       356.0   \n",
      "2  2022-01-03       869.0       390.0       327.0       213.0       387.0   \n",
      "3  2022-01-04       630.0       381.0       332.0       175.0        93.0   \n",
      "4  2022-01-05       552.0       320.0       225.0       108.0       135.0   \n",
      "\n",
      "   GB00012055  GB00013035  GB00013039  GB00013587  ...  GB10060567  \\\n",
      "0         0.0         0.0         0.0       322.0  ...         NaN   \n",
      "1       360.0       276.0       152.0       532.0  ...         NaN   \n",
      "2       317.0       385.0       236.0       614.0  ...         NaN   \n",
      "3       369.0       296.0       229.0       500.0  ...         NaN   \n",
      "4       353.0       234.0       126.0       372.0  ...         NaN   \n",
      "\n",
      "   GB10060720  GB10060991  GB10061194  GB10061691  GB10061793  GB10061892  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   GB10061900  GB10061901  GB10061989  \n",
      "0         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN  \n",
      "\n",
      "[5 rows x 249 columns]\n",
      "        GB00010023   GB00010062  GB00011039   GB00012044   GB00012047  \\\n",
      "count   543.000000  1088.000000  284.000000  1009.000000  1033.000000   \n",
      "mean    449.220994   367.945772  234.679577   115.535183   207.551791   \n",
      "std     283.928397   166.459119   83.725782    91.104755   126.568414   \n",
      "min       0.000000     0.000000    0.000000     0.000000     0.000000   \n",
      "25%     273.000000   247.750000  181.000000    67.000000   111.000000   \n",
      "50%     365.000000   317.000000  211.500000    91.000000   177.000000   \n",
      "75%     523.000000   445.000000  268.500000   132.000000   275.000000   \n",
      "max    2157.000000  1044.000000  650.000000   814.000000   830.000000   \n",
      "\n",
      "        GB00012055   GB00013035   GB00013039   GB00013587   GB00014024  ...  \\\n",
      "count  1087.000000  1086.000000   860.000000  1079.000000   496.000000  ...   \n",
      "mean    332.949402   205.390424   175.350000   595.849861   377.425403  ...   \n",
      "std     168.917445   149.001879   132.932877   337.111502   118.332601  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%     223.000000   120.000000   104.000000   377.000000   298.000000  ...   \n",
      "50%     278.000000   155.000000   133.500000   499.000000   366.000000  ...   \n",
      "75%     392.500000   228.750000   192.000000   713.000000   445.250000  ...   \n",
      "max    1287.000000  1081.000000  1052.000000  2389.000000  1074.000000  ...   \n",
      "\n",
      "       GB10060567   GB10060720  GB10060991   GB10061194   GB10061691  \\\n",
      "count  397.000000   218.000000  203.000000    53.000000    61.000000   \n",
      "mean   154.738035   621.068807  205.586207   460.509434   446.049180   \n",
      "std     82.646026   443.317406  144.423183   237.660846   250.682696   \n",
      "min      3.000000     0.000000    0.000000     0.000000     0.000000   \n",
      "25%    103.000000   302.250000  118.000000   297.000000   262.000000   \n",
      "50%    131.000000   503.000000  150.000000   394.000000   388.000000   \n",
      "75%    183.000000   776.500000  244.500000   615.000000   595.000000   \n",
      "max    785.000000  2564.000000  830.000000  1181.000000  1144.000000   \n",
      "\n",
      "       GB10061793  GB10061892   GB10061900  GB10061901  GB10061989  \n",
      "count   88.000000   44.000000    31.000000    47.00000    7.000000  \n",
      "mean   158.443182  224.659091   694.838710   475.06383  497.571429  \n",
      "std     93.735119  115.195676   407.608398   365.64573  118.210063  \n",
      "min      0.000000    0.000000     0.000000     0.00000  390.000000  \n",
      "25%     90.750000  158.750000   414.500000   218.50000  403.500000  \n",
      "50%    135.500000  195.500000   591.000000   362.00000  428.000000  \n",
      "75%    195.750000  250.250000   999.500000   623.50000  590.500000  \n",
      "max    440.000000  567.000000  1583.000000  1883.00000  677.000000  \n",
      "\n",
      "[8 rows x 248 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "!pip install pandas\n",
    "!pip install holidays\n",
    "import pandas as pd\n",
    "import holidays\n",
    "\n",
    "# Define the file path from OneDrive\n",
    "file_path = r\"C:\\Users\\caham\\OneDrive - Pandora\\Desktop\\Thesis\\Master Thesis\\Datasets\\all_stores_grid.csv\"\n",
    "\n",
    "# Load the Excel file into a Pandas DataFrame\n",
    "traffic_df = pd.read_csv(file_path)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "print(traffic_df.head())\n",
    "\n",
    "# Get summary statistics of the 'Visitors CY' column\n",
    "print(traffic_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa0a6fe-5ca0-4660-b9f1-06a07ee06b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date           object\n",
      "GB00010023    float64\n",
      "GB00010062    float64\n",
      "GB00011039    float64\n",
      "GB00012044    float64\n",
      "               ...   \n",
      "GB10061793    float64\n",
      "GB10061892    float64\n",
      "GB10061900    float64\n",
      "GB10061901    float64\n",
      "GB10061989    float64\n",
      "Length: 249, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(traffic_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32be3938-886c-4391-8a5e-bc10f127836e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  GB00010023  GB00010062  GB00011039  GB00012044  GB00012047  \\\n",
      "0  2022-01-01       449.0         0.0       158.0         0.0         0.0   \n",
      "1  2022-01-02       748.0       367.0       275.0       207.0       356.0   \n",
      "2  2022-01-03       869.0       390.0       327.0       213.0       387.0   \n",
      "3  2022-01-04       630.0       381.0       332.0       175.0        93.0   \n",
      "4  2022-01-05       552.0       320.0       225.0       108.0       135.0   \n",
      "\n",
      "   GB00012055  GB00013035  GB00013039  GB00013587  ...  GB10060567  \\\n",
      "0         0.0         0.0         0.0       322.0  ...         0.0   \n",
      "1       360.0       276.0       152.0       532.0  ...         0.0   \n",
      "2       317.0       385.0       236.0       614.0  ...         0.0   \n",
      "3       369.0       296.0       229.0       500.0  ...         0.0   \n",
      "4       353.0       234.0       126.0       372.0  ...         0.0   \n",
      "\n",
      "   GB10060720  GB10060991  GB10061194  GB10061691  GB10061793  GB10061892  \\\n",
      "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "   GB10061900  GB10061901  GB10061989  \n",
      "0         0.0         0.0         0.0  \n",
      "1         0.0         0.0         0.0  \n",
      "2         0.0         0.0         0.0  \n",
      "3         0.0         0.0         0.0  \n",
      "4         0.0         0.0         0.0  \n",
      "\n",
      "[5 rows x 249 columns]\n",
      "        GB00010023   GB00010062   GB00011039   GB00012044   GB00012047  \\\n",
      "count  1096.000000  1096.000000  1096.000000  1096.000000  1096.000000   \n",
      "mean    222.561131   365.260036    60.811131   106.364051   195.621350   \n",
      "std     300.656773   168.784148   111.330640    92.827732   132.037382   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000   246.000000     0.000000    61.000000   100.000000   \n",
      "50%       0.000000   315.000000     0.000000    86.000000   169.500000   \n",
      "75%     362.250000   444.000000   140.500000   128.000000   267.000000   \n",
      "max    2157.000000  1044.000000   650.000000   814.000000   830.000000   \n",
      "\n",
      "        GB00012055   GB00013035   GB00013039   GB00013587   GB00014024  ...  \\\n",
      "count  1096.000000  1096.000000  1096.000000  1096.000000  1096.000000  ...   \n",
      "mean    330.215328   203.516423   137.592153   586.607664   170.805657  ...   \n",
      "std     170.886635   149.601283   138.067017   342.500103   204.093106  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%     222.000000   120.000000    74.750000   372.000000     0.000000  ...   \n",
      "50%     277.000000   154.000000   117.000000   494.000000     0.000000  ...   \n",
      "75%     391.000000   225.500000   167.000000   704.000000   352.000000  ...   \n",
      "max    1287.000000  1081.000000  1052.000000  2389.000000  1074.000000  ...   \n",
      "\n",
      "        GB10060567   GB10060720   GB10060991   GB10061194   GB10061691  \\\n",
      "count  1096.000000  1096.000000  1096.000000  1096.000000  1096.000000   \n",
      "mean     56.050182   123.533759    38.078467    22.269161    24.825730   \n",
      "std      89.480072   316.963105   101.153598   111.581531   117.941158   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%     108.250000     0.000000     0.000000     0.000000     0.000000   \n",
      "max     785.000000  2564.000000   830.000000  1181.000000  1144.000000   \n",
      "\n",
      "        GB10061793   GB10061892   GB10061900   GB10061901   GB10061989  \n",
      "count  1096.000000  1096.000000  1096.000000  1096.000000  1096.000000  \n",
      "mean     12.721715     9.019161    19.653285    20.372263     3.177920  \n",
      "std      50.533231    49.676695   133.542640   122.016565    40.609672  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "max     440.000000   567.000000  1583.000000  1883.000000   677.000000  \n",
      "\n",
      "[8 rows x 248 columns]\n",
      "date           object\n",
      "GB00010023    float64\n",
      "GB00010062    float64\n",
      "GB00011039    float64\n",
      "GB00012044    float64\n",
      "               ...   \n",
      "GB10061793    float64\n",
      "GB10061892    float64\n",
      "GB10061900    float64\n",
      "GB10061901    float64\n",
      "GB10061989    float64\n",
      "Length: 249, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Fill all NaN values in the dataset with 0s\n",
    "traffic_df = traffic_df.fillna(0)\n",
    "\n",
    "# Show the first few rows to verify changes\n",
    "print(traffic_df.head())\n",
    "\n",
    "# Get summary statistics to check if NaNs were replaced\n",
    "print(traffic_df.describe())\n",
    "\n",
    "# Check data types after filling NaNs\n",
    "print(traffic_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d28d2e-c6fa-4ab4-acae-95c37ab7106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  GB00011039\n",
      "284 2022-10-12         0.0\n"
     ]
    }
   ],
   "source": [
    "# Convert 'date' column to datetime format if not already\n",
    "traffic_df['date'] = pd.to_datetime(traffic_df['date'])\n",
    "\n",
    "# Filter the dataset for Store ID 'GB00011039' on '2022-10-12'\n",
    "specific_value = traffic_df.loc[traffic_df['date'] == \"2022-10-12\", ['date', 'GB00011039']]\n",
    "\n",
    "# Display the result\n",
    "print(specific_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a16e5deb-6045-43ea-b707-89e7c84985fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date    store_id  visitors_cy\n",
      "0 2022-01-01  GB00010023          449\n",
      "1 2022-01-02  GB00010023          748\n",
      "2 2022-01-03  GB00010023          869\n",
      "3 2022-01-04  GB00010023          630\n",
      "4 2022-01-05  GB00010023          552\n"
     ]
    }
   ],
   "source": [
    "# Convert all store visitor columns to integers (excluding the date column)\n",
    "store_columns = traffic_df.columns[1:]  # Exclude the 'date' column\n",
    "traffic_df[store_columns] = traffic_df[store_columns].astype(int)\n",
    "\n",
    "# Now melt the dataframe\n",
    "df_long = traffic_df.melt(id_vars=['date'], var_name='store_id', value_name='visitors_cy')\n",
    "\n",
    "# Convert 'date' to datetime if needed\n",
    "df_long['date'] = pd.to_datetime(df_long['date'])\n",
    "\n",
    "# Display the first few rows\n",
    "print(df_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8eae39e-26bd-4259-a6bc-ca7820dcb7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "47067\n"
     ]
    }
   ],
   "source": [
    "print(df_long['visitors_cy'].isna().sum())  # Count NaNs (blanks)\n",
    "print((df_long['visitors_cy'] == 0).sum())  # Count zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3226b7b-b595-46cf-82e7-2cccd40ccb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       store_id  visitor_count\n",
      "33   GB00019140           1096\n",
      "6    GB00013035           1096\n",
      "182  GB10051443           1096\n",
      "86   GB00130847           1096\n",
      "156  GB10049392           1096\n"
     ]
    }
   ],
   "source": [
    "# Count the number of values in 'visitors_cy' per Store ID\n",
    "visitor_counts = df_long.groupby('store_id')['visitors_cy'].count().reset_index()\n",
    "visitor_counts.columns = ['store_id', 'visitor_count']\n",
    "\n",
    "# Display 5 random store IDs with their visitor counts\n",
    "random_sample = visitor_counts.sample(n=5, random_state=42)  # Set random_state for reproducibility\n",
    "\n",
    "print(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea77ca4-5d14-4fca-9376-317ae8672259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have checked that the dataset has now included all the dates that orignially had blanks as a value (just replaced with zero)\n",
    "# This is because our dataset had a total of 1096 dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7766089-6375-4c80-9313-be9dcd7fd17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Store ID                 Store Name Store Status Cluster Country  \\\n",
      "0  US10060444  Chesterfield Towne Center         OPEN     NAM      US   \n",
      "1  US10060441           Coastland Center         OPEN     NAM      US   \n",
      "2  US10060289             Southgate Mall         OPEN     NAM      US   \n",
      "3  US10059911          125th St - Harlem         OPEN     NAM      US   \n",
      "4  US10061059         Macy's @ Flushing          OPEN     NAM      US   \n",
      "\n",
      "       City           State Ownership     Location Type Store Type   \\\n",
      "0  Richmond  US -  Virginia       O&O     Shopping Mall          CS   \n",
      "1    Naples   US -  Florida       O&O     Shopping Mall          CS   \n",
      "2  Missoula   US -  Montana       O&O     Shopping Mall          CS   \n",
      "3  New York  US -  New York       O&O   Street Location          CS   \n",
      "4  New York  US -  New York       O&O  Department Store         SIS   \n",
      "\n",
      "  Store Design Concept Location strength Unit of Measurement  Total Area  \\\n",
      "0       EVOKE 2.0 CORE                 A                 SQF  138.797142   \n",
      "1       EVOKE 2.0 CORE                 C                 SQF  149.666797   \n",
      "2       EVOKE 2.0 CORE                 C                 SQF  120.309437   \n",
      "3       EVOKE 2.0 CORE                 A                 SQF  187.849947   \n",
      "4       EVOKE 2.0 CORE             Other                 SQF   23.225760   \n",
      "\n",
      "   Sales Area  \n",
      "0  104.144308  \n",
      "1  112.226872  \n",
      "2   90.208852  \n",
      "3  148.644864  \n",
      "4   23.225760  \n",
      "Index(['date', 'store_id', 'visitors_cy'], dtype='object')\n",
      "Index(['Store ID', 'Store Name', 'Store Status', 'Cluster', 'Country', 'City',\n",
      "       'State', 'Ownership', 'Location Type', 'Store Type ',\n",
      "       'Store Design Concept', 'Location strength', 'Unit of Measurement',\n",
      "       'Total Area', 'Sales Area'],\n",
      "      dtype='object')\n",
      "        date    store_id  visitors_cy Store Name Store Status Cluster Country  \\\n",
      "0 2022-01-01  GB00010023          449        NaN          NaN     NaN     NaN   \n",
      "1 2022-01-02  GB00010023          748        NaN          NaN     NaN     NaN   \n",
      "2 2022-01-03  GB00010023          869        NaN          NaN     NaN     NaN   \n",
      "3 2022-01-04  GB00010023          630        NaN          NaN     NaN     NaN   \n",
      "4 2022-01-05  GB00010023          552        NaN          NaN     NaN     NaN   \n",
      "\n",
      "  City State Ownership Location Type Store Type  Store Design Concept  \\\n",
      "0  NaN   NaN       NaN           NaN         NaN                  NaN   \n",
      "1  NaN   NaN       NaN           NaN         NaN                  NaN   \n",
      "2  NaN   NaN       NaN           NaN         NaN                  NaN   \n",
      "3  NaN   NaN       NaN           NaN         NaN                  NaN   \n",
      "4  NaN   NaN       NaN           NaN         NaN                  NaN   \n",
      "\n",
      "  Location strength Unit of Measurement  Total Area  Sales Area  \n",
      "0               NaN                 NaN         NaN         NaN  \n",
      "1               NaN                 NaN         NaN         NaN  \n",
      "2               NaN                 NaN         NaN         NaN  \n",
      "3               NaN                 NaN         NaN         NaN  \n",
      "4               NaN                 NaN         NaN         NaN  \n",
      "Merged data saved as StoreTraffic_Data.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the file path for the store data\n",
    "store_file_path = r\"C:\\Users\\caham\\OneDrive - Pandora\\Desktop\\Thesis\\Master Thesis\\Datasets\\Store data.xlsx\"\n",
    "\n",
    "# Load the Excel file into a Pandas DataFrame for store data\n",
    "store_df = pd.read_excel(store_file_path, engine=\"openpyxl\")\n",
    "\n",
    "# Show the first few rows of the store DataFrame\n",
    "print(store_df.head())\n",
    "\n",
    "# Ensure the column names match before merging\n",
    "print(df_long.columns)  # Check traffic data column names\n",
    "print(store_df.columns)  # Check store data column names\n",
    "\n",
    "# If necessary, rename columns for consistency\n",
    "store_df.rename(columns={'Store ID': 'store_id'}, inplace=True)  # Adjust if needed\n",
    "\n",
    "# Perform a left join on the 'store_id' column\n",
    "StoreTraffic_df = df_long.merge(store_df, on='store_id', how='left')\n",
    "\n",
    "# Show the merged DataFrame\n",
    "print(StoreTraffic_df.head())\n",
    "\n",
    "# Optionally, save the merged dataset\n",
    "StoreTraffic_df.to_csv(\"StoreTraffic_Data.csv\", index=False)\n",
    "print(\"Merged data saved as StoreTraffic_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3cec9c8-cc4c-4486-8533-273f02756c7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date    store_id  visitors_cy Store Name Store Status Cluster  \\\n",
      "1096 2022-01-01  GB00010062            0      Derby         OPEN    BRIT   \n",
      "1097 2022-01-02  GB00010062          367      Derby         OPEN    BRIT   \n",
      "1098 2022-01-03  GB00010062          390      Derby         OPEN    BRIT   \n",
      "1099 2022-01-04  GB00010062          381      Derby         OPEN    BRIT   \n",
      "1100 2022-01-05  GB00010062          320      Derby         OPEN    BRIT   \n",
      "...         ...         ...          ...        ...          ...     ...   \n",
      "2187 2024-12-27  GB00010062          609      Derby         OPEN    BRIT   \n",
      "2188 2024-12-28  GB00010062          648      Derby         OPEN    BRIT   \n",
      "2189 2024-12-29  GB00010062          706      Derby         OPEN    BRIT   \n",
      "2190 2024-12-30  GB00010062          744      Derby         OPEN    BRIT   \n",
      "2191 2024-12-31  GB00010062          720      Derby         OPEN    BRIT   \n",
      "\n",
      "     Country   City State Ownership    Location Type Store Type   \\\n",
      "1096      GB  Derby   NaN       O&O  Shopping Center          CS   \n",
      "1097      GB  Derby   NaN       O&O  Shopping Center          CS   \n",
      "1098      GB  Derby   NaN       O&O  Shopping Center          CS   \n",
      "1099      GB  Derby   NaN       O&O  Shopping Center          CS   \n",
      "1100      GB  Derby   NaN       O&O  Shopping Center          CS   \n",
      "...      ...    ...   ...       ...              ...         ...   \n",
      "2187      GB  Derby   NaN       O&O  Shopping Center          CS   \n",
      "2188      GB  Derby   NaN       O&O  Shopping Center          CS   \n",
      "2189      GB  Derby   NaN       O&O  Shopping Center          CS   \n",
      "2190      GB  Derby   NaN       O&O  Shopping Center          CS   \n",
      "2191      GB  Derby   NaN       O&O  Shopping Center          CS   \n",
      "\n",
      "     Store Design Concept Location strength Unit of Measurement  Total Area  \\\n",
      "1096            EVOLUTION                 A                 SQM       127.0   \n",
      "1097            EVOLUTION                 A                 SQM       127.0   \n",
      "1098            EVOLUTION                 A                 SQM       127.0   \n",
      "1099            EVOLUTION                 A                 SQM       127.0   \n",
      "1100            EVOLUTION                 A                 SQM       127.0   \n",
      "...                   ...               ...                 ...         ...   \n",
      "2187            EVOLUTION                 A                 SQM       127.0   \n",
      "2188            EVOLUTION                 A                 SQM       127.0   \n",
      "2189            EVOLUTION                 A                 SQM       127.0   \n",
      "2190            EVOLUTION                 A                 SQM       127.0   \n",
      "2191            EVOLUTION                 A                 SQM       127.0   \n",
      "\n",
      "      Sales Area  \n",
      "1096        82.0  \n",
      "1097        82.0  \n",
      "1098        82.0  \n",
      "1099        82.0  \n",
      "1100        82.0  \n",
      "...          ...  \n",
      "2187        82.0  \n",
      "2188        82.0  \n",
      "2189        82.0  \n",
      "2190        82.0  \n",
      "2191        82.0  \n",
      "\n",
      "[1096 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# CHecking to make sure the data is accurate compared to our inital dataset -- filter on a specific ID for BRIT\n",
    "\n",
    "specific_store_id = \"GB00010062\"\n",
    "filtered_df = StoreTraffic_df[StoreTraffic_df['store_id'] == specific_store_id]\n",
    "\n",
    "# Display the filtered data\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a436e-4080-434d-92e5-66a72d4ca24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conducting some EDA now to understand more of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe75b61-a741-4cd7-939a-ebca5b6a53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7476b8-6a7c-4326-86e1-0670fa053940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install holidays package and get public holidays\n",
    "!pip install holidays\n",
    "\n",
    "# Function to get holidays for a country\n",
    "def get_holidays(country_code):\n",
    "    # Get the holidays for the given country and years\n",
    "    holiday_instance = holidays.CountryHoliday(country_code, years=[2022, 2023, 2024, 2025])\n",
    "    \n",
    "    # Return a list of holidays\n",
    "    return list(holiday_instance)\n",
    "\n",
    "# Example usage for Great Britain\n",
    "holidays_in_gb = get_holidays(\"GB\")\n",
    "print(holidays_in_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d5161-637f-4af6-a160-52931736c90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
